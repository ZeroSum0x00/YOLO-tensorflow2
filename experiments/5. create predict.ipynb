{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"mount_file_id":"1eFApnIo4Yx-JvVEsOjGPmE5DGwsgjPZA","authorship_tag":"ABX9TyMSyR93pdQjLVZU8D7MP0O8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bBWozrjG4MOc","executionInfo":{"status":"ok","timestamp":1662788389594,"user_tz":-420,"elapsed":585,"user":{"displayName":"Nguyễn Ích Thanh Tú","userId":"09234871255042424318"}},"outputId":"6206fb4c-2934-4560-c828-199b268ea01d"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Object Detection/Yolo/Yolo - Tensorflow 2 - v2\n"]}],"source":["%cd \"/content/drive/MyDrive/Object Detection/Yolo/Yolo - Tensorflow 2 - v2\""]},{"cell_type":"code","source":["import os\n","import cv2\n","import colorsys\n","import numpy as np\n","from PIL import Image\n","from PIL import ImageDraw, ImageFont\n","\n","from models.yolo import YOLO\n","from models.yolov3 import YOLOv3Encoder, YOLOv3Decoder\n","from visualizer.visual_image import visual_image\n","from visualizer.visual_value import tensor_value_info\n","from google.colab.patches import cv2_imshow"],"metadata":{"id":"rBF2Jrnw4U0z","executionInfo":{"status":"ok","timestamp":1662788403456,"user_tz":-420,"elapsed":13864,"user":{"displayName":"Nguyễn Ích Thanh Tú","userId":"09234871255042424318"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def resize_image(image, target_size, letterbox_image):\n","    h, w, _    = image.shape\n","    ih, iw, _  = target_size\n","    if letterbox_image:\n","        scale = min(iw/w, ih/h)\n","        nw, nh  = int(scale * w), int(scale * h)\n","        dw, dh = (iw - nw) // 2, (ih - nh) // 2\n","        image_resized = cv2.resize(image, (nw, nh))\n","        image_paded = np.full(shape=[ih, iw, 3], fill_value=128.0, dtype=image.dtype)\n","        image_paded[dh:nh+dh, dw:nw+dw, :] = image_resized\n","        return image_paded\n","    else:\n","        image = cv2.resize(image, (iw, ih))\n","        return image"],"metadata":{"id":"vqydddQ14WFi","executionInfo":{"status":"ok","timestamp":1662788403457,"user_tz":-420,"elapsed":13,"user":{"displayName":"Nguyễn Ích Thanh Tú","userId":"09234871255042424318"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def preprocess_input(image):\n","    image /= 255.0\n","    return image"],"metadata":{"id":"XzclxSAk4XFI","executionInfo":{"status":"ok","timestamp":1662788403458,"user_tz":-420,"elapsed":13,"user":{"displayName":"Nguyễn Ích Thanh Tú","userId":"09234871255042424318"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def detect_image(img_name, model, target_shape, class_names, crop=False, count=False, letterbox_image=False):\n","    num_classes = len(class_names)\n","    hsv_tuples  = [(x / num_classes, 1., 1.) for x in range(num_classes)]\n","    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n","    colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n","\n","    image = cv2.imread(img_name)\n","    \n","    original_shape = [image.shape[1], image.shape[0]]\n","    image_shape = original_shape\n","\n","    image_data  = resize_image(image, (target_shape[0], target_shape[1], 3), letterbox_image)\n","    image_data  = preprocess_input(image_data.astype(np.float32))\n","\n","    image_data  = np.expand_dims(image_data, axis=0)\n","    out_boxes, out_scores, out_classes = model.predict(image_data, original_shape) \n","\n","    print('Found {} boxes for {}'.format(len(out_boxes), 'img'))\n","\n","    bbox_thick = int(0.6 * (original_shape[0] + original_shape[1]) / 1000)\n","    if bbox_thick < 1: bbox_thick = 1\n","    fontScale = 0.75 * bbox_thick\n","\n","    if crop:\n","        dir_save_path = \"/content/sample_data/img_crop\"\n","        if not os.path.exists(dir_save_path):\n","            os.makedirs(dir_save_path)\n","\n","        for i, c in list(enumerate(out_boxes)):\n","            x_min, y_min, x_max, y_max = out_boxes[i]\n","            x_min = max(0, np.floor(x_min).astype('int32'))\n","            y_min = max(0, np.floor(y_min).astype('int32'))\n","            x_max = min(image_shape[0], np.floor(x_max).astype('int32'))\n","            y_max = min(image_shape[1], np.floor(y_max).astype('int32'))\n","            crop_image = image[y_min:y_max, x_min:x_max]\n","            cv2.imwrite(os.path.join(dir_save_path, \"crop_\" + str(i) + \".png\"), crop_image)\n","            print(\"save crop_\" + str(i) + \".png to \" + dir_save_path)\n","          \n","    if count:\n","        print(\"top_label:\", out_classes)\n","        classes_nums    = np.zeros([num_classes])\n","        for i in range(num_classes):\n","            num = np.sum(out_classes == i)\n","            if num > 0:\n","                print(class_names[i], \" : \", num)\n","            classes_nums[i] = num\n","        print(\"classes_nums:\", classes_nums)\n","\n","\n","    for i, c in list(enumerate(out_classes)):\n","        predicted_class = class_names[int(c)]\n","        box             = out_boxes[i]\n","        score           = out_scores[i]\n","\n","        x_min, y_min, x_max, y_max = box\n","        x_min = max(0, np.floor(x_min).astype('int32'))\n","        y_min = max(0, np.floor(y_min).astype('int32'))\n","        x_max = min(image_shape[0], np.floor(x_max).astype('int32'))\n","        y_max = min(image_shape[1], np.floor(y_max).astype('int32'))\n","\n","        label = '{} {:.2f}'.format(predicted_class, score)\n","        print(label, x_min, y_min, x_max, y_max)\n","\n","        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), colors[c], bbox_thick*2)\n","\n","        (text_width, text_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_COMPLEX_SMALL, fontScale, thickness=bbox_thick)\n","        # put filled text rectangle\n","        cv2.rectangle(image, (x_min, y_min), (x_min + text_width, y_min - text_height - baseline), colors[c], thickness=cv2.FILLED)\n","\n","        # put text above rectangle\n","        cv2.putText(image, label, (x_min, y_min - 4), cv2.FONT_HERSHEY_COMPLEX_SMALL, fontScale, (0,0,0), bbox_thick, lineType=cv2.LINE_AA)\n","    cv2_imshow(image)\n","    return image"],"metadata":{"id":"Wo-b4G7H4YC4","executionInfo":{"status":"ok","timestamp":1662788404039,"user_tz":-420,"elapsed":593,"user":{"displayName":"Nguyễn Ích Thanh Tú","userId":"09234871255042424318"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def get_anchors(anchors_path):\n","    '''loads the anchors from a file'''\n","    with open(anchors_path, encoding='utf-8') as f:\n","        anchors = f.readline()\n","    anchors = [float(x) for x in anchors.split(',')]\n","    anchors = np.array(anchors).reshape(-1, 2)\n","    return anchors, len(anchors)\n","\n","def get_classes(classes_path):\n","    with open(classes_path, encoding='utf-8') as f:\n","        class_names = f.readlines()\n","    class_names = [c.strip() for c in class_names]\n","    return class_names, len(class_names)"],"metadata":{"id":"AimVg6a94aKh","executionInfo":{"status":"ok","timestamp":1662788404040,"user_tz":-420,"elapsed":12,"user":{"displayName":"Nguyễn Ích Thanh Tú","userId":"09234871255042424318"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["classes_path                        = './saved_weights/voc_classes.txt'\n","\n","train_annotation_path               = '/content/sample_data/OD_xml_tiny/train.txt'\n","val_annotation_path                 = '/content/sample_data/OD_xml_tiny/validation.txt'\n","anchors_path                        = './configs/yolo_anchors.txt'\n","anchors_mask                        = [[6, 7, 8], [3, 4, 5], [0, 1, 2]]\n","\n","input_shape                         = [416, 416]\n","\n","load_type                          = \"weights\"\n","\n","weight_objects                    = [        \n","                                    {\n","                                        'path': './saved_weights/checkpoints/last_epoch_weights',\n","                                        'stage': 'full',\n","                                        'custom_objects': None\n","                                    }\n","                                ]"],"metadata":{"id":"fhQdQPT_4bEx","executionInfo":{"status":"ok","timestamp":1662788404041,"user_tz":-420,"elapsed":12,"user":{"displayName":"Nguyễn Ích Thanh Tú","userId":"09234871255042424318"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["class_names, num_classes            = get_classes(classes_path)\n","anchors, num_anchors                = get_anchors(anchors_path)"],"metadata":{"id":"T7jEOSZg4cFj","executionInfo":{"status":"ok","timestamp":1662788405117,"user_tz":-420,"elapsed":1087,"user":{"displayName":"Nguyễn Ích Thanh Tú","userId":"09234871255042424318"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["encoder = YOLOv3Encoder(num_classes, num_anchor=3, darknet_weight=None)\n","decoder = YOLOv3Decoder(anchors,\n","              num_classes,\n","              input_shape,\n","              anchors_mask,\n","              max_boxes = 100,\n","              confidence = 0.3,\n","              nms_iou = 0.3,\n","              letterbox_image=True)\n","\n","model = YOLO(encoder, decoder)\n","\n","if load_type and weight_objects:\n","    if load_type == \"weights\":\n","        model.load_weights(weight_objects)\n","    elif load_type == \"models\":\n","        model.load_models(weight_objects)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h_2JYN-k4c_Z","executionInfo":{"status":"ok","timestamp":1662788417284,"user_tz":-420,"elapsed":12173,"user":{"displayName":"Nguyễn Ích Thanh Tú","userId":"09234871255042424318"}},"outputId":"38c1bc06-1f8d-431d-adfe-7a0d79aaba69"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-09-10 05:40:16,770 - INFO - Load yolo weights from ./saved_weights/checkpoints/last_epoch_weights\n","INFO:YOLO:Load yolo weights from ./saved_weights/checkpoints/last_epoch_weights\n"]}]},{"cell_type":"code","source":["image = \"/content/drive/MyDrive/Object Detection/Yolo/Yolo_pythonlessons/IMAGES/street2.jpg\"\n","\n","img = detect_image(image, model, input_shape, class_names, crop=False, count=False, letterbox_image=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1VPM_izynBrfHw699NzxzPMpJ4MlY0ArH"},"id":"qaLrysiC4d-J","executionInfo":{"status":"ok","timestamp":1662788430036,"user_tz":-420,"elapsed":12764,"user":{"displayName":"Nguyễn Ích Thanh Tú","userId":"09234871255042424318"}},"outputId":"1c93dfe3-7b14-4193-ebbf-db7795f04819"},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}